{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from adv_finance import stats, labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.style.use('bmh')\n",
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/nfs/data/interim_2018/TRADE_A233740_DB.parq')\n",
    "df = df.loc[~df.index.duplicated(keep='first')]\n",
    "data = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66183, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.99 s, sys: 0 ns, total: 2.99 s\n",
      "Wall time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "daily_vol = stats.get_daily_vol(data['close'])\n",
    "t_events = labeling.cusum_filter(data['close'], daily_vol.mean()) \n",
    "v_barriers = labeling.add_vertical_barrier(t_events=t_events, close=data['close'], num_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/code/adv_finance/adv_finance/labeling/labeling.py:111: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  target = target.loc[t_events]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76.4 ms, sys: 63.1 ms, total: 139 ms\n",
      "Wall time: 711 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-09 09:30:31.639098 100.0 apply_pt_sl_on_t1 done after 0.01 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pt_sl = [1,1]\n",
    "min_ret = 0.01\n",
    "\n",
    "t_barrier_events = labeling.get_events(close=data['close'], \n",
    "                                      t_events=t_events, \n",
    "                                      pt_sl=pt_sl, \n",
    "                                      num_threads=16, \n",
    "                                      target=daily_vol, \n",
    "                                      min_ret=min_ret, \n",
    "                                      vertical_barrier_times=v_barriers, \n",
    "                                      side_prediction=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labeling.get_bins(t_barrier_events, data['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:00:03.348</th>\n",
       "      <td>19800</td>\n",
       "      <td>19980</td>\n",
       "      <td>19800</td>\n",
       "      <td>19980</td>\n",
       "      <td>215968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:00:15.776</th>\n",
       "      <td>19980</td>\n",
       "      <td>20015</td>\n",
       "      <td>19980</td>\n",
       "      <td>20005</td>\n",
       "      <td>51025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:00:39.990</th>\n",
       "      <td>20005</td>\n",
       "      <td>20065</td>\n",
       "      <td>20005</td>\n",
       "      <td>20045</td>\n",
       "      <td>49957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:01:11.518</th>\n",
       "      <td>20045</td>\n",
       "      <td>20075</td>\n",
       "      <td>20040</td>\n",
       "      <td>20050</td>\n",
       "      <td>50140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:01:30.166</th>\n",
       "      <td>20050</td>\n",
       "      <td>20080</td>\n",
       "      <td>20045</td>\n",
       "      <td>20080</td>\n",
       "      <td>54775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          open   high    low  close     vol\n",
       "timestamp                                                  \n",
       "2018-01-02 10:00:03.348  19800  19980  19800  19980  215968\n",
       "2018-01-02 10:00:15.776  19980  20015  19980  20005   51025\n",
       "2018-01-02 10:00:39.990  20005  20065  20005  20045   49957\n",
       "2018-01-02 10:01:11.518  20045  20075  20040  20050   50140\n",
       "2018-01-02 10:01:30.166  20050  20080  20045  20080   54775"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = v_barriers\n",
    "features = data.loc[t_barrier_events.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(features.index.difference(y.index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.620468987240725 1.9641701628337827\n",
      "CPU times: user 2.53 s, sys: 0 ns, total: 2.53 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = []\n",
    "for _ in range(10):   \n",
    "    clf = RandomForestClassifier()\n",
    "    kfold = KFold(n_splits=10, shuffle=False)\n",
    "    scores.append(cross_val_score(clf, features, labels['bin'], cv=kfold, scoring='neg_log_loss'))\n",
    "print(np.mean(scores), np.var(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PurgedKFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection._split import _BaseKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_times(t1, test_times): \n",
    "    trn = t1.copy(deep=True)\n",
    "    for i, j in test_times.iteritems(): \n",
    "        df0 = trn[(i <= trn.index) & (trn.index <= j)].index \n",
    "        df1 = trn[(i <= trn) & (trn <= j)].index\n",
    "        df2 = trn[(trn.index <= i) & (j <= trn)].index\n",
    "        trn = trn.drop(df0.union(df1.union(df2)))\n",
    "        \n",
    "    return trn\n",
    "    \n",
    "\n",
    "class PurgedKFold(_BaseKFold): \n",
    "    def __init__(self, n_splits=3, t1=None, pct_embargo=0., purging=True): \n",
    "        if not isinstance(t1, pd.Series): \n",
    "            raise ValueError('Label through dates must be a pd.Series')\n",
    "        \n",
    "        super(PurgedKFold, self).__init__(n_splits=n_splits, shuffle=False, random_state=None)\n",
    "        \n",
    "        self.t1 = t1\n",
    "        self.pct_embargo = pct_embargo\n",
    "        self.purging = purging \n",
    "        \n",
    "            \n",
    "    def split(self, X, y=None, groups=None): \n",
    "        if (X.index == self.t1.index).sum() != len(self.t1): \n",
    "            raise ValueError('X and t1 must have the same index')\n",
    "        \n",
    "        indices = np.arange(X.shape[0])\n",
    "        \n",
    "        # Embargo width \n",
    "        embg_size = int(X.shape[0] * self.pct_embargo)\n",
    "        test_ranges = [(i[0], i[-1] + 1) for i in np.array_split(indices, self.n_splits)]\n",
    "        for st, end in test_ranges: \n",
    "            # Test dta \n",
    "            test_indices = indices[st:end]\n",
    "            \n",
    "            # Training data prior to test data \n",
    "            t0 = self.t1.index[st]\n",
    "            train_indices = self.t1.index.searchsorted(self.t1[self.t1 <= t0].index)\n",
    "            \n",
    "            # Add training data after test data \n",
    "            max_t1_idx = self.t1.index.searchsorted(self.t1[test_indices].max())\n",
    "            if max_t1_idx < X.shape[0]: \n",
    "                train_indices = np.concatenate((train_indices, indices[max_t1_idx + embg_size:]))\n",
    "                \n",
    "            # Purging \n",
    "            if self.purging: \n",
    "                train_t1 = t1.iloc[train_indices]\n",
    "                test_t1 = t1.iloc[test_indices]\n",
    "                train_t1 = get_train_times(train_t1, test_t1)\n",
    "                train_indices = self.t1.index.searchsorted(train_t1.index)\n",
    "                \n",
    "            yield train_indices, test_indices\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score \n",
    "from adv_finance.sampling import get_sample_tw, get_num_co_events\n",
    "\n",
    "\n",
    "def cv_score(clf, X, y, sample_weight=None, scoring='neg_log_loss', t1=None, \n",
    "             n_splits=3, cv_gen=None, pct_embargo=0., purging=False): \n",
    "    \n",
    "    if scoring not in ['neg_log_loss', 'accuracy']:\n",
    "        raise Exception('Wrong scoring method') \n",
    "        \n",
    "    if cv_gen is None: \n",
    "        cv_gen = PurgedKFold(n_splits=n_splits, t1=t1, \n",
    "                            pct_embargo=pct_embargo,\n",
    "                            purging=purging)\n",
    "    scores = []\n",
    "    for train, test in cv_gen.split(X=X): \n",
    "        train_params = dict()\n",
    "        test_params = dict() \n",
    "\n",
    "        # Sample weight is an optional parametr \n",
    "        if sample_weight is not None: \n",
    "            train_params['sample_weight'] = sample_weight.iloc[train].values \n",
    "            test_params['sample_weight'] = sample_weight.iloc[test].values \n",
    "\n",
    "        clf_ = clf.fit(X=X.iloc[train, :], y=y.iloc[train], **train_params)\n",
    "\n",
    "        # Scoring \n",
    "        if scoring == 'neg_log_loss': \n",
    "            prob = clf_.predict_proba(X.iloc[test, :])\n",
    "            score_ = -log_loss(y.iloc[test], prob, labels=clf.classes_, **test_params)\n",
    "        else: \n",
    "            pred = clf_.predict(X.iloc[test, :])\n",
    "            score_ = accuracy_score(y.iloc[test], pred, **test_params)\n",
    "        scores.append(score_)\n",
    "\n",
    "    return np.array(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python372/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \"\"\"\n",
      "/opt/conda/envs/python372/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.563392057237702 1.7638123497155294\n",
      "CPU times: user 5.97 s, sys: 0 ns, total: 5.97 s\n",
      "Wall time: 5.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "t1_ = t1.loc[features.index]\n",
    "\n",
    "scores = [] \n",
    "for _ in range(100): \n",
    "    scores_ = cv_score(clf, features, labels['bin'], pct_embargo=0.01, t1=t1_, purging=False)\n",
    "    scores.append(np.mean(scores_))\n",
    "    \n",
    "print(np.mean(scores), np.var(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sample Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 ms, sys: 36 ms, total: 48 ms\n",
      "Wall time: 347 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-09 16:22:11.767111 100.0 mp_num_co_events done after 0.0 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_co_events = get_num_co_events(t_barrier_events.index, t1, num_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = get_sample_tw(t1, n_co_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = sample_weight.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.94468863147859 2.3983148799868714\n",
      "CPU times: user 6.15 s, sys: 0 ns, total: 6.15 s\n",
      "Wall time: 6.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = []\n",
    "for _ in range(100):\n",
    "    scores_ = cv_score(clf, features, labels['bin'], sample_weight=sample_weight,\n",
    "                       pct_embargo=0.01, t1=t1_, purging=False)\n",
    "    scores.append(np.mean(scores_))\n",
    "print(np.mean(scores), np.var(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.815097225517478 2.649720007024885\n",
      "CPU times: user 6.25 s, sys: 0 ns, total: 6.25 s\n",
      "Wall time: 6.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = []\n",
    "for _ in range(100):\n",
    "    scores_ = cv_score(clf, features, labels['bin'], sample_weight=sample_weight,\n",
    "                       pct_embargo=0., t1=t1_, purging=False)\n",
    "    scores.append(np.mean(scores_))\n",
    "print(np.mean(scores), np.var(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
